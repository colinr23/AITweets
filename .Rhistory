numTypes <- 55    #number of subtypes for Hall    107-161
xx <- x[startWeek:length(Hall[,1]),c(1:3, 107:161)]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[107:161]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes, 3)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_end.csv", xx)
numTypes <- 52    #number of subtypes for Hall    162-213
xx <- x[startWeek:length(Hall[,1]),c(1:3, 162:213)]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[162:213]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes, 3)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_animal.csv", xx)
numTypes <- 13    #number of subtypes for Hall    162-213
xx <- x[startWeek:length(Hall[,1]),c(1:3, 214:226)]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[214:226]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes, 3)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_food.csv", xx)
allLabs <- names(x)[4:226]
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- allLabs[seq(2,length(allLabs),2)]
#x1 <- read.csv("H_all.csv")
x2 <- read.csv("H_end.csv")
x3 <- read.csv("H_animal.csv")
x4 <- read.csv("H_food.csv")
xxx2 <- x2[,which(names(x2)=="Hend_4512i_Far"):length(names(x2))]
xxx3 <- x3[,which(names(x3)=="ACt_4512i_Far"):length(names(x3))]
xxx4 <- x4[,which(names(x4)=="Fch_4512i_Far"):length(names(x4))]
xxx <- cbind(xxx2, xxx3, xxx4)  #all outbreak data
names(xxx)
numTypes <- 103    #number of subtypes for Hall
xx <- x[startWeek:length(Hall[,1]),1:106]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[4:106]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_all.csv", xx)
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#*************************************************************
#HHHHHHHHHHHEEEEEEEEEEEEEEEEEEEENNNNNNNNNNNNNNNNNNNNNNNNNNNNDDDDDDDDDDDDDDDDDDDD
numTypes <- 55    #number of subtypes for Hall    107-161
xx <- x[startWeek:length(Hall[,1]),c(1:3, 107:161)]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[107:161]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_end.csv", xx)
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#*************************************************************
#AAAAAAAAAAAAAAAAAAAAANNNNNNNNNNNNNNNNIIIIIIIIIIIIMMMMMMMMMMMMMMMMMMAAAAAAAAAALLLLLLLLLLLLLLL
numTypes <- 52    #number of subtypes for Hall    162-213
xx <- x[startWeek:length(Hall[,1]),c(1:3, 162:213)]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[162:213]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_animal.csv", xx)
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#*************************************************************
#ffffffffffffffffoooooooooooooooooooooooooooooooooooooooooooooooddddddddddddddddddddddddd
numTypes <- 13    #number of subtypes for Hall    162-213
xx <- x[startWeek:length(Hall[,1]),c(1:3, 214:226)]
outmat <- matrix(nrow=T, ncol=numTypes)
ii <- 1
lbs <- names(x)[214:226]
lbsx <- vector(length=length(lbs))
for(i in seq(1,numTypes)) {
outmat[,i] <- out.f[[ii]]$alarm
lbsx[i] <- paste(lbs[ii], "_Far", sep="")
ii <- ii + 1
}
outdf <- data.frame(outmat)
names(outdf) <- lbsx
xx <- cbind(xx, outdf)
write.csv(file="H_food.csv", xx)
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#*************************************************************
allLabs <- names(x)[4:226]
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- allLabs[seq(2,length(allLabs),2)]
#x1 <- read.csv("H_all.csv")
x2 <- read.csv("H_end.csv")
x3 <- read.csv("H_animal.csv")
x4 <- read.csv("H_food.csv")
xxx2 <- x2[,which(names(x2)=="Hend_4512i_Far"):length(names(x2))]
xxx3 <- x3[,which(names(x3)=="ACt_4512i_Far"):length(names(x3))]
xxx4 <- x4[,which(names(x4)=="Fch_4512i_Far"):length(names(x4))]
xxx <- cbind(xxx2, xxx3, xxx4)  #all outbreak data
names(xxx)
species
allLabs[55]
x2 <- read.csv("H_end.csv")
x3 <- read.csv("H_animal.csv")
x4 <- read.csv("H_food.csv")
xxx2 <- x2[,which(names(x2)=="Hend_4512i_Far"):length(names(x2))]
xxx3 <- x3[,which(names(x3)=="ACt_4512i_Far"):length(names(x3))]
xxx4 <- x4[,which(names(x4)=="Fch_4512i_Far"):length(names(x4))]
xxx <- cbind(xxx2, xxx3, xxx4)  #all outbreak data
#for each disease
#for each time period
#if set new outbreak then findConcurrent outbreaks
allLabs <- names(xxx)
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- allLabs[seq(2,length(allLabs),2)]
ct <- vector(length=length(xxx[,1]))
ct[] <- 0
for(i in 1:length(xxx[1,])) {      #for each disease
for(t in 1:length(xxx[,1])) {                       #for each time
if(xxx[t,i] > 0) {                                                 #outbreak
if(i < which(names(xxx)=="ACt_4512i_Far")) { species = "human" }
if(i >= which(names(xxx)=="ACt_4512i_Far") & i < which(names(xxx)=="Fch_4512i_Far")) { species = "animal" }
if(i >= which(names(xxx)=="Fch_4512i_Far")) { species = "food" }
subtype = unlist(strsplit(names(xxx)[i], "_"))[2]
ct[t] <- ct[t] + findConcurrentOutbreaks(species, subtype, t)          #are there outbreaks in this subtype in the other two????
}
}
}
t
i
species
indices <- 55 + as.numeric(which(allLabs[55:length(allLabs)] == subtype))
indices
indices <- 55 + (as.numeric(which(allLabs[55:length(allLabs)] == subtype)))
indices
as.numeric(which(allLabs[55:length(allLabs)] == subtype))
which(allLabs[55:length(allLabs)] == subtype)
head(allLabs)
allLabs <- names(xxx)
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
head(allLabs)
sapply(FUN=strsplit, allLabs, "_")
allLabs <- names(xxx)
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- allLabs[seq(2,length(allLabs),3)]
allLabs
allLabs <- c(allLabs[seq(2,length(allLabs),3)])
allLabs
allLabs <- names(xxx)
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- c(allLabs[seq(2,length(allLabs),3)])
ct <- vector(length=length(xxx[,1]))
ct[] <- 0
for(i in 1:length(xxx[1,])) {      #for each disease
for(t in 1:length(xxx[,1])) {                       #for each time
if(xxx[t,i] > 0) {                                                 #outbreak
if(i < which(names(xxx)=="ACt_4512i_Far")) { species = "human" }
if(i >= which(names(xxx)=="ACt_4512i_Far") & i < which(names(xxx)=="Fch_4512i_Far")) { species = "animal" }
if(i >= which(names(xxx)=="Fch_4512i_Far")) { species = "food" }
subtype = unlist(strsplit(names(xxx)[i], "_"))[2]
ct[t] <- ct[t] + findConcurrentOutbreaks(species, subtype, t)          #are there outbreaks in this subtype in the other two????
}
}
}
t
i
species
subtype
xxx[t,i]
indices <- 55 + as.numeric(which(allLabs[55:length(allLabs)] == subtype))
indices
which(allLabs[55:length(allLabs)] == subtype)
allLabs[55:length(allLabs)]
head(allLabs[55:length(allLabs)])
allLabs <- names(xxx)
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- c(allLabs[seq(2,length(allLabs),3)])
head(allLabs[55:length(allLabs)])
c?
?
]
?c
allLabs <- names(xxx)
allLabs <- unlist(sapply(FUN=strsplit, allLabs, "_"))
allLabs <- as.vector(allLabs[seq(2,length(allLabs),3)])
head(allLabs[55:length(allLabs)])
which(allLabs[55:length(allLabs)] == subtype)
allLabs[55:length(allLabs)]
subtype
which(allLabs[55:length(allLabs)] == subtype)
which(allLabs[55:length(allLabs)] == subtype) >= 0
(which(allLabs[55:length(allLabs)] == subtype) >= 0) == TRUE
library(surveillance)
date
date()
date() <= date() +45
date() <= as.Date(date()) + 45
as.Date(date()) <= as.Date(date()) + 45
getwd()
setwd("C:/Users/crobertson/Dropbox/nsercCREATE/Scraping/tweets/outputs/AITweets")
x <- read.csv("test2_clean.csv")
names(x)
x$D <- as.POSIXct(strptime(as.character(x$created_at), "%a %b %d %H:%M:%S %z %Y"))
x$day <- as.Date(x$D)
library(plyr)
library(ggplot2)
x$textC <- removeURL(x$text)
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
library(plyr)
library(ggplot2)
x$D <- as.POSIXct(strptime(as.character(x$created_at), "%a %b %d %H:%M:%S %z %Y"))
x$day <- as.Date(x$D)
x$textC <- removeURL(x$text)
x <- x[!duplicated(x$textC), ]
daily <- ddply(x, .(day), summarise, numTweets = length(day)) #summarize by mean
head(daily)
dim(daily)
which(daily$day <= date())
date()
max(daily$day)
max(daily$day)-7
max(daily$day)-28
dim(daily)
recent <- subset(daily, day >= max(daily$day)-28)
dim(recent)
recent <- subset(daily, day >= max(daily$day)-21)
dim(recent)
require(XML)
install.packages('XML')
install.packages('tm')
install.packages('Wordcloud')
install.packages('wordcloud')
install.packages('RColorBrewer')
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
daily <- ddply(x, .(day), summarise, numTweets = length(day)) #summarize by mean
x <- read.csv("test2_clean.csv")
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
library(plyr)
library(ggplot2)
library(XML)
library(tm)
library(wordcloud)
library(RColorBrewer)
x$D <- as.POSIXct(strptime(as.character(x$created_at), "%a %b %d %H:%M:%S %z %Y"))
x$day <- as.Date(x$D)
x$textC <- removeURL(x$text)
x <- x[!duplicated(x$textC), ]
daily <- ddply(x, .(day), summarise, numTweets = length(day)) #summarize by mean
ggplot(daily, aes(day, numTweets)) + geom_line() + xlab("") + ylab("Daily AI-related Tweets")
recent <- subset(daily, day >= max(daily$day)-14)
ggplot(recent, aes(day, numTweets)) + geom_line() + xlab("") + ylab("Daily AI-related Tweets - last 14 days")
recent14 <- subset(daily, day >= max(daily$day)-14)
recent7 <- subset(daily, day >= max(daily$day)-7)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
table(ap.d$freq)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
?wordcloud
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
head(x)
recent14 <- subset(x, day >= max(daily$day)-14)
recent7 <- subset(x, day >= max(daily$day)-7)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
table(ap.d$freq)
recent14 <- subset(x, day >= max(x$day)-14)
recent7 <- subset(x, day >= max(x$day)-7)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
#table(ap.d$freq)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
?wordcloud
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2, cex=0.6)
class(ap.d)
head(ap.d)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
class(ap.corpus)
head(ap.corpus)
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- Corpus(VectorSource(ap.corpus))
head(ap.corpus)
ap.corpus
ap.tdm <- TermDocumentMatrix(ap.corpus)
wordcloud(ap.corpus, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2, cex=0.6)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
inspect(ap.corpus)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- tm_map(ap.corpus,stemDocument)
install.packages('snowballMC')
install.packages('snowballC')
install.packages('SnowballC')
ap.corpus <- tm_map(ap.corpus,stemDocument)
wordcloud(ap.corpus, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
#ap.corpus <- tm_map(ap.corpus, tolower)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
#ap.corpus <- tm_map(ap.corpus,stemDocument)
ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2, cex=0.6)
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
?removeWords
recent14 <- subset(x, day >= max(x$day)-14)
recent7 <- subset(x, day >= max(x$day)-7)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, c('bird flu', 'avian influenza', 'avian flu', 'poultry disease')))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
#table(ap.d$freq)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, c('bird', 'flu', 'avian', 'influenza', 'poultry')))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
ap.corpus <- tm_map(ap.corpus, removeWords, c('bird', 'flu', 'avian', 'influenza', 'poultry'))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
#table(ap.d$freq)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
warnings()
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
inspect(ap.corpus)
head(inspect(ap.corpus))
recent14 <- subset(x, day >= max(x$day)-14)
recent7 <- subset(x, day >= max(x$day)-7)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
table(ap.d$freq)
head(ap.d)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
#ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
head(ap.d)
ap.corpus[[1]]
ap.corpus[1]
rm(ap.corpus)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
table(ap.d$freq)
head(ap.d)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
#ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
#ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
head(ap.d)
ap.corpus <- Corpus(DataframeSource(data.frame(recent14$text)))
ap.corpus <- tm_map(ap.corpus, content_transformer(tolower))
ap.corpus <- tm_map(ap.corpus, removeWords, stopwords("english"))
ap.corpus <- tm_map(ap.corpus, removeWords, c("bird", "flu", "avian", "influenza", "poultry"))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, PlainTextDocument)
ap.corpus <- tm_map(ap.corpus, stemDocument)
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
head(ap.d)
wordcloud(ap.d$word,ap.d$freq, scale=c(6,.2),min.freq=3,max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
x <- c(25, 35, 17, 21, 24, 37, 26, 46, 58, 30, 32, 13, 12, 38, 41, 43, 44, 22, 53, 27)
summary(x)
sort(x)
sort(x)[1:9]
sort(x)[1:10]
median(sort(x)[1:10])
16/6
x <- c(1,4,2,1,6,2)
y <- c(2,1,5,6,2,1)
mean(x)
mean(y)
x <- c(25, 35, 17, 21, 24, 37, 26, 46, 58, 30, 32, 13, 12, 38, 41, 43, 44, 22, 53, 27)
sort(x)
